[core]
no_lock = True
log_level = INFO

[worker]
keep_alive = False
ping_interval = 20
wait_interval = 20
max_reschedules = 3

[DEFAULT]
name = KingMaker

; grid storage protocol and path usable from submitting machine and worker nodes of cluster
; job in- and output will be stored in $wlcg_path under subdirectory of analysis $name
wlcg_path = srm://cmssrm-kit.gridka.de:8443/srm/managerv2?SFN=/pnfs/gridka.de/cms/disk-only/store/user/sbrommer/CROWN_samples
xrootd_path = root://cmsxrootd-redirectors.gridka.de//store/user/sbrommer/CROWN_samples

; default htcondor job submission configuration (modifiable for each task)
htcondor_accounting_group = cms.higgs
htcondor_remote_job = True
; TODO: Set your user proxy to your personal one 
htcondor_user_proxy = /home/sbrommer/.globus/x509up
htcondor_request_cpus = 1
; for all cores in total
htcondor_universe = docker
htcondor_docker_image = mschnepf/slc7-condocker
; create log files in htcondor jobs
transfer_logs = True
; set local scheduler
local_scheduler = True
; set tolerance for workflow success with failed branches
tolerance = 0.00
acceptance = 1.00
; submit only missing htcondor workflow branches (should always be true)
only_missing = True

; bootstrap file to be sourced at beginning of htcondor jobs (relative PATH to framework.py)
bootstrap_file = setup_lawcrown.sh


[CROWNBuild]
# sampletype = samples
# era = era
channels = mt
shifts = all
build_dir = build
install_dir = tarballs

[CROWNRun]
bootstrap_file = setup_lawcrown.sh
; HTCondor
htcondor_walltime = 10800
htcondor_request_memory = 2500
htcondor_requirements = TARGET.ProvidesCPU && TARGET.ProvidesIO
htcondor_request_disk = 2000000

[ProduceSamples]
dataset_database = sample_database/datasets.yaml

[ConfigureDatasets]
dataset_database = sample_database/datasets.yaml